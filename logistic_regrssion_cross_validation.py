# -*- coding: utf-8 -*-
"""Logistic Regrssion cross validation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f-nFpwp1eJDbwm6Q3mlowEOV-z8vCoWR

#**Logistic regression Cross validation**

**Cross validation**

- example : the person has a disease(actual val), but the model predicts he doesnt have = False negative -then type 2 error

- example :the person doesnt has a disease (actual), but the model predicts he  have = False positive -then type 1 error
"""

import pandas as pd
import numpy as np

df =pd.read_csv ("https://raw.githubusercontent.com/krishnaik06/Types-Of-Cross-Validation/main/cancer_dataset.csv")

df.head()

X =df.iloc[:,2:]
y =df.iloc[:,1]

X.drop(columns =['Unnamed: 32'],inplace =True)

"""#spliting the data"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size =0.3 ,random_state =0)
model =LogisticRegression()

model.fit(X_train,y_train)

res = model.score(X_test,y_test)
res
#0.9532163742690059
#this gives fluctuatioins in accuracy, so use cross validation in classification

"""#Cross validation
 - k fold
"""

from sklearn.model_selection import KFold,cross_val_score

k =KFold(10)

model =LogisticRegression()
result = cross_val_score(model,X,y,cv =k)
print(result)


#values : [0.84210526 0.94736842 0.94736842 0.9122807  0.96491228 0.96491228
# 0.96491228 0.94736842 0.92982456 0.96428571]

print(np.mean(result)) # we can achieve 95 percent accuracy, when k =10

"""#stratified"""

from sklearn.model_selection import StratifiedKFold

stra = StratifiedKFold(n_splits = 15)
model = LogisticRegression()
re = cross_val_score(model,X,y,cv =stra)

print(np.mean(re))

"""LOOCV -Leave One Out CV"""

from sklearn.model_selection import LeaveOneOut

Lev = LeaveOneOut()
model =LogisticRegression()
res1 = cross_val_score(model,X,y,cv =Lev)

print(np.mean(res1))